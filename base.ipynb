{
  "cells": [
    {
      "cell_type": "code",
      "id": "yU4rzHLCmu6Jcmgdg8czdRca",
      "metadata": {
        "tags": [],
        "id": "yU4rzHLCmu6Jcmgdg8czdRca",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747042984870,
          "user_tz": 240,
          "elapsed": 7356,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "from telnetlib import PRAGMA_HEARTBEAT\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "import os\n",
        "from typing import Dict\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GradualWarmupScheduler(_LRScheduler):\n",
        "    def __init__(self, optimizer, multiplier, warm_epoch, after_scheduler=None):\n",
        "        self.multiplier = multiplier\n",
        "        self.total_epoch = warm_epoch\n",
        "        self.after_scheduler = after_scheduler\n",
        "        self.finished = False\n",
        "        self.last_epoch = None\n",
        "        self.base_lrs = None\n",
        "        super().__init__(optimizer)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self.last_epoch > self.total_epoch:\n",
        "            if self.after_scheduler:\n",
        "                if not self.finished:\n",
        "                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
        "                    self.finished = True\n",
        "                return self.after_scheduler.get_lr()\n",
        "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
        "        return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "    def step(self, epoch=None, metrics=None):\n",
        "        if self.finished and self.after_scheduler:\n",
        "            if epoch is None:\n",
        "                self.after_scheduler.step(None)\n",
        "            else:\n",
        "                self.after_scheduler.step(epoch - self.total_epoch)\n",
        "        else:\n",
        "            return super(GradualWarmupScheduler, self).step(epoch)"
      ],
      "metadata": {
        "id": "s9dguYR_YTiJ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747042984870,
          "user_tz": 240,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "s9dguYR_YTiJ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_connect(x, drop_ratio):\n",
        "    keep_ratio = 1.0 - drop_ratio\n",
        "    mask = torch.empty([x.shape[0], 1, 1, 1], dtype=x.dtype, device=x.device)\n",
        "    mask.bernoulli_(p=keep_ratio)\n",
        "    x.div_(keep_ratio)\n",
        "    x.mul_(mask)\n",
        "    return x\n",
        "\n",
        "class Swish(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class TimeEmbedding(nn.Module):\n",
        "    def __init__(self, T, d_model, dim):\n",
        "        assert d_model % 2 == 0\n",
        "        super().__init__()\n",
        "        emb = torch.arange(0, d_model, step=2) / d_model * math.log(10000)\n",
        "        emb = torch.exp(-emb)\n",
        "        pos = torch.arange(T).float()\n",
        "        emb = pos[:, None] * emb[None, :]\n",
        "        assert list(emb.shape) == [T, d_model // 2]\n",
        "        emb = torch.stack([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
        "        assert list(emb.shape) == [T, d_model // 2, 2]\n",
        "        emb = emb.view(T, d_model)\n",
        "\n",
        "        self.timembedding = nn.Sequential(\n",
        "            nn.Embedding.from_pretrained(emb, freeze=False),\n",
        "            nn.Linear(d_model, dim),\n",
        "            Swish(),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, t):\n",
        "        emb = self.timembedding(t)\n",
        "        return emb\n",
        "\n",
        "\n",
        "class ConditionalEmbedding(nn.Module):\n",
        "    def __init__(self, num_labels, d_model, dim):\n",
        "        assert d_model % 2 == 0\n",
        "        super().__init__()\n",
        "        self.condEmbedding = nn.Sequential(\n",
        "            nn.Embedding(num_embeddings=num_labels + 1, embedding_dim=d_model, padding_idx=0),\n",
        "            nn.Linear(d_model, dim),\n",
        "            Swish(),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, t):\n",
        "        emb = self.condEmbedding(t)\n",
        "        return emb\n",
        "\n",
        "\n",
        "class DownSample(nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super().__init__()\n",
        "        self.c1 = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
        "        self.c2 = nn.Conv2d(in_ch, in_ch, 5, stride=2, padding=2)\n",
        "\n",
        "    def forward(self, x, temb, cemb):\n",
        "        x = self.c1(x) + self.c2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UpSample(nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super().__init__()\n",
        "        self.c = nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1)\n",
        "        self.t = nn.ConvTranspose2d(in_ch, in_ch, 5, 2, 2, 1)\n",
        "\n",
        "    def forward(self, x, temb, cemb):\n",
        "        _, _, H, W = x.shape\n",
        "        x = self.t(x)\n",
        "        x = self.c(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttnBlock(nn.Module):\n",
        "    def __init__(self, in_ch):\n",
        "        super().__init__()\n",
        "        self.group_norm = nn.GroupNorm(32, in_ch)\n",
        "        self.proj_q = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.proj_k = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.proj_v = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "        self.proj = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        h = self.group_norm(x)\n",
        "        q = self.proj_q(h)\n",
        "        k = self.proj_k(h)\n",
        "        v = self.proj_v(h)\n",
        "\n",
        "        q = q.permute(0, 2, 3, 1).view(B, H * W, C)\n",
        "        k = k.view(B, C, H * W)\n",
        "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
        "        assert list(w.shape) == [B, H * W, H * W]\n",
        "        w = F.softmax(w, dim=-1)\n",
        "\n",
        "        v = v.permute(0, 2, 3, 1).view(B, H * W, C)\n",
        "        h = torch.bmm(w, v)\n",
        "        assert list(h.shape) == [B, H * W, C]\n",
        "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
        "        h = self.proj(h)\n",
        "\n",
        "        return x + h\n",
        "\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, tdim, dropout, attn=True):\n",
        "        super().__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.GroupNorm(32, in_ch),\n",
        "            Swish(),\n",
        "            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),\n",
        "        )\n",
        "        self.temb_proj = nn.Sequential(\n",
        "            Swish(),\n",
        "            nn.Linear(tdim, out_ch),\n",
        "        )\n",
        "        self.cond_proj = nn.Sequential(\n",
        "            Swish(),\n",
        "            nn.Linear(tdim, out_ch),\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.GroupNorm(32, out_ch),\n",
        "            Swish(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n",
        "        )\n",
        "        if in_ch != out_ch:\n",
        "            self.shortcut = nn.Conv2d(in_ch, out_ch, 1, stride=1, padding=0)\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "        if attn:\n",
        "            self.attn = AttnBlock(out_ch)\n",
        "        else:\n",
        "            self.attn = nn.Identity()\n",
        "\n",
        "\n",
        "    def forward(self, x, temb, labels):\n",
        "        h = self.block1(x)\n",
        "        h += self.temb_proj(temb)[:, :, None, None]\n",
        "        h += self.cond_proj(labels)[:, :, None, None]\n",
        "        h = self.block2(h)\n",
        "\n",
        "        h = h + self.shortcut(x)\n",
        "        h = self.attn(h)\n",
        "        return h\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, T, num_labels, ch, ch_mult, num_res_blocks, dropout):\n",
        "        super().__init__()\n",
        "        tdim = ch * 4\n",
        "        self.time_embedding = TimeEmbedding(T, ch, tdim)\n",
        "        self.cond_embedding = ConditionalEmbedding(num_labels, ch, tdim)\n",
        "        self.head = nn.Conv2d(3, ch, kernel_size=3, stride=1, padding=1)\n",
        "        self.downblocks = nn.ModuleList()\n",
        "        chs = [ch]  # record output channel when dowmsample for upsample\n",
        "        now_ch = ch\n",
        "        for i, mult in enumerate(ch_mult):\n",
        "            out_ch = ch * mult\n",
        "            for _ in range(num_res_blocks):\n",
        "                self.downblocks.append(ResBlock(in_ch=now_ch, out_ch=out_ch, tdim=tdim, dropout=dropout))\n",
        "                now_ch = out_ch\n",
        "                chs.append(now_ch)\n",
        "            if i != len(ch_mult) - 1:\n",
        "                self.downblocks.append(DownSample(now_ch))\n",
        "                chs.append(now_ch)\n",
        "\n",
        "        self.middleblocks = nn.ModuleList([\n",
        "            ResBlock(now_ch, now_ch, tdim, dropout, attn=True),\n",
        "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
        "        ])\n",
        "\n",
        "        self.upblocks = nn.ModuleList()\n",
        "        for i, mult in reversed(list(enumerate(ch_mult))):\n",
        "            out_ch = ch * mult\n",
        "            for _ in range(num_res_blocks + 1):\n",
        "                self.upblocks.append(ResBlock(in_ch=chs.pop() + now_ch, out_ch=out_ch, tdim=tdim, dropout=dropout, attn=False))\n",
        "                now_ch = out_ch\n",
        "            if i != 0:\n",
        "                self.upblocks.append(UpSample(now_ch))\n",
        "        assert len(chs) == 0\n",
        "\n",
        "        self.tail = nn.Sequential(\n",
        "            nn.GroupNorm(32, now_ch),\n",
        "            Swish(),\n",
        "            nn.Conv2d(now_ch, 3, 3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x, t, labels):\n",
        "        # Timestep embedding\n",
        "        temb = self.time_embedding(t)\n",
        "        cemb = self.cond_embedding(labels)\n",
        "        # Downsampling\n",
        "        h = self.head(x)\n",
        "        hs = [h]\n",
        "        for layer in self.downblocks:\n",
        "            h = layer(h, temb, cemb)\n",
        "            hs.append(h)\n",
        "        # Middle\n",
        "        for layer in self.middleblocks:\n",
        "            h = layer(h, temb, cemb)\n",
        "        # Upsampling\n",
        "        for layer in self.upblocks:\n",
        "            if isinstance(layer, ResBlock):\n",
        "                h = torch.cat([h, hs.pop()], dim=1)\n",
        "            h = layer(h, temb, cemb)\n",
        "        h = self.tail(h)\n",
        "\n",
        "        assert len(hs) == 0\n",
        "        return h"
      ],
      "metadata": {
        "id": "ukZRzW25YYhI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747042984870,
          "user_tz": 240,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "ukZRzW25YYhI",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(v, t, x_shape):\n",
        "    \"\"\"\n",
        "    Extract some coefficients at specified timesteps, then reshape to\n",
        "    [batch_size, 1, 1, 1, 1, ...] for broadcasting purposes.\n",
        "    \"\"\"\n",
        "    device = t.device\n",
        "    out = torch.gather(v, index=t, dim=0).float().to(device)\n",
        "    return out.view([t.shape[0]] + [1] * (len(x_shape) - 1))\n",
        "\n",
        "\n",
        "class GaussianDiffusionTrainer(nn.Module):\n",
        "    def __init__(self, model, beta_1, beta_T, T):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.T = T\n",
        "\n",
        "        self.register_buffer(\n",
        "            'betas', torch.linspace(beta_1, beta_T, T).double())\n",
        "        alphas = 1. - self.betas\n",
        "        alphas_bar = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "        self.register_buffer(\n",
        "            'sqrt_alphas_bar', torch.sqrt(alphas_bar))\n",
        "        self.register_buffer(\n",
        "            'sqrt_one_minus_alphas_bar', torch.sqrt(1. - alphas_bar))\n",
        "\n",
        "    def forward(self, x_0, labels):\n",
        "        \"\"\"\n",
        "        Algorithm 1.\n",
        "        \"\"\"\n",
        "        t = torch.randint(self.T, size=(x_0.shape[0], ), device=x_0.device)\n",
        "        noise = torch.randn_like(x_0)\n",
        "        x_t =   extract(self.sqrt_alphas_bar, t, x_0.shape) * x_0 + \\\n",
        "                extract(self.sqrt_one_minus_alphas_bar, t, x_0.shape) * noise\n",
        "        loss = F.mse_loss(self.model(x_t, t, labels), noise, reduction='none')\n",
        "        return loss\n",
        "\n",
        "\n",
        "class GaussianDiffusionSampler(nn.Module):\n",
        "    def __init__(self, model, beta_1, beta_T, T, w = 0.):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = model\n",
        "        self.T = T\n",
        "        ### In the classifier free guidence paper, w is the key to control the gudience.\n",
        "        ### w = 0 and with label = 0 means no guidence.\n",
        "        ### w > 0 and label > 0 means guidence. Guidence would be stronger if w is bigger.\n",
        "        self.w = w\n",
        "\n",
        "        self.register_buffer('betas', torch.linspace(beta_1, beta_T, T).double())\n",
        "        alphas = 1. - self.betas\n",
        "        alphas_bar = torch.cumprod(alphas, dim=0)\n",
        "        alphas_bar_prev = F.pad(alphas_bar, [1, 0], value=1)[:T]\n",
        "        self.register_buffer('coeff1', torch.sqrt(1. / alphas))\n",
        "        self.register_buffer('coeff2', self.coeff1 * (1. - alphas) / torch.sqrt(1. - alphas_bar))\n",
        "        self.register_buffer('posterior_var', self.betas * (1. - alphas_bar_prev) / (1. - alphas_bar))\n",
        "\n",
        "    def predict_xt_prev_mean_from_eps(self, x_t, t, eps):\n",
        "        assert x_t.shape == eps.shape\n",
        "        return extract(self.coeff1, t, x_t.shape) * x_t - extract(self.coeff2, t, x_t.shape) * eps\n",
        "\n",
        "    def p_mean_variance(self, x_t, t, labels):\n",
        "        # below: only log_variance is used in the KL computations\n",
        "        var = torch.cat([self.posterior_var[1:2], self.betas[1:]])\n",
        "        var = extract(var, t, x_t.shape)\n",
        "        eps = self.model(x_t, t, labels)\n",
        "        nonEps = self.model(x_t, t, torch.zeros_like(labels).to(labels.device))\n",
        "        eps = (1. + self.w) * eps - self.w * nonEps\n",
        "        xt_prev_mean = self.predict_xt_prev_mean_from_eps(x_t, t, eps=eps)\n",
        "        return xt_prev_mean, var\n",
        "\n",
        "    def forward(self, x_T, labels):\n",
        "        \"\"\"\n",
        "        Algorithm 2.\n",
        "        \"\"\"\n",
        "        x_t = x_T\n",
        "        for time_step in reversed(range(self.T)):\n",
        "            print(time_step)\n",
        "            t = x_t.new_ones([x_T.shape[0], ], dtype=torch.long) * time_step\n",
        "            mean, var= self.p_mean_variance(x_t=x_t, t=t, labels=labels)\n",
        "            if time_step > 0:\n",
        "                noise = torch.randn_like(x_t)\n",
        "            else:\n",
        "                noise = 0\n",
        "            x_t = mean + torch.sqrt(var) * noise\n",
        "            assert torch.isnan(x_t).int().sum() == 0, \"nan in tensor.\"\n",
        "        x_0 = x_t\n",
        "        return torch.clip(x_0, -1, 1)"
      ],
      "metadata": {
        "id": "ANQTqUU8Yh8K",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747042986987,
          "user_tz": 240,
          "elapsed": 170,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "ANQTqUU8Yh8K",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(modelConfig: Dict):\n",
        "    device = torch.device(modelConfig[\"device\"])\n",
        "    # dataset\n",
        "    dataset = CIFAR10(\n",
        "        root='./CIFAR10', train=True, download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]))\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=modelConfig[\"batch_size\"], shuffle=True, num_workers=4, drop_last=True, pin_memory=True)\n",
        "\n",
        "    # model setup\n",
        "    net_model = UNet(T=modelConfig[\"T\"], num_labels=10, ch=modelConfig[\"channel\"], ch_mult=modelConfig[\"channel_mult\"],\n",
        "                     num_res_blocks=modelConfig[\"num_res_blocks\"], dropout=modelConfig[\"dropout\"]).to(device)\n",
        "    if modelConfig[\"training_load_weight\"] is not None:\n",
        "        net_model.load_state_dict(torch.load(os.path.join(\n",
        "            modelConfig[\"save_dir\"], modelConfig[\"training_load_weight\"]), map_location=device), strict=False)\n",
        "        print(\"Model weight load down.\")\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        net_model.parameters(), lr=modelConfig[\"lr\"], weight_decay=1e-4)\n",
        "    cosineScheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer=optimizer, T_max=modelConfig[\"epoch\"], eta_min=0, last_epoch=-1)\n",
        "    warmUpScheduler = GradualWarmupScheduler(optimizer=optimizer, multiplier=modelConfig[\"multiplier\"],\n",
        "                                             warm_epoch=modelConfig[\"epoch\"] // 10, after_scheduler=cosineScheduler)\n",
        "    trainer = GaussianDiffusionTrainer(\n",
        "        net_model, modelConfig[\"beta_1\"], modelConfig[\"beta_T\"], modelConfig[\"T\"]).to(device)\n",
        "\n",
        "    # start training\n",
        "    losses = []\n",
        "    lrs = []\n",
        "    for e in range(modelConfig[\"epoch\"]):\n",
        "        epoch_losses = []\n",
        "        epoch_lrs = []\n",
        "        with tqdm(dataloader, dynamic_ncols=True) as tqdmDataLoader:\n",
        "            for images, labels in tqdmDataLoader:\n",
        "                # train\n",
        "                b = images.shape[0]\n",
        "                optimizer.zero_grad()\n",
        "                x_0 = images.to(device)\n",
        "                labels = labels.to(device) + 1\n",
        "                if np.random.rand() < 0.1:\n",
        "                    labels = torch.zeros_like(labels).to(device)\n",
        "                loss = trainer(x_0, labels).sum() / b ** 2.\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    net_model.parameters(), modelConfig[\"grad_clip\"])\n",
        "                optimizer.step()\n",
        "                loss_item = loss.item()\n",
        "                lr = optimizer.state_dict()['param_groups'][0][\"lr\"]\n",
        "                epoch_lrs.append(lr)\n",
        "                epoch_losses.append(loss_item)\n",
        "                tqdmDataLoader.set_postfix(ordered_dict={\n",
        "                    \"epoch\": e,\n",
        "                    \"loss: \": loss_item,\n",
        "                    \"img shape: \": x_0.shape,\n",
        "                    \"LR\": lr\n",
        "                })\n",
        "            tqdmDataLoader.set_postfix(ordered_dict={\n",
        "                \"epoch\": e,\n",
        "                \"loss: \": np.mean(epoch_losses),\n",
        "                \"img shape: \": x_0.shape,\n",
        "                \"LR\": np.mean(epoch_lrs)\n",
        "            })\n",
        "        warmUpScheduler.step()\n",
        "        losses.append(np.mean(epoch_losses))\n",
        "        lrs.append(np.mean(epoch_lrs))\n",
        "        torch.save(net_model.state_dict(), os.path.join(\n",
        "            modelConfig[\"save_dir\"], 'ckpt_' + str(e) + \"_.pt\"))\n",
        "    print(losses)\n",
        "    print(lrs)\n",
        "    with open('./data.txt', 'w') as f:\n",
        "        f.write(f\"{losses}\\n{lrs}\")\n",
        "\n",
        "\n",
        "def eval(modelConfig: Dict):\n",
        "    device = torch.device(modelConfig[\"device\"])\n",
        "    # load model and evaluate\n",
        "    with torch.no_grad():\n",
        "        step = int(modelConfig[\"batch_size\"] // 10)\n",
        "        labelList = []\n",
        "        k = 0\n",
        "        for i in range(1, modelConfig[\"batch_size\"] + 1):\n",
        "            labelList.append(torch.ones(size=[1]).long() * k)\n",
        "            if i % step == 0:\n",
        "                if k < 10 - 1:\n",
        "                    k += 1\n",
        "        labels = torch.cat(labelList, dim=0).long().to(device) + 1\n",
        "        print(\"labels: \", labels)\n",
        "        model = UNet(T=modelConfig[\"T\"], num_labels=10, ch=modelConfig[\"channel\"], ch_mult=modelConfig[\"channel_mult\"],\n",
        "                     num_res_blocks=modelConfig[\"num_res_blocks\"], dropout=modelConfig[\"dropout\"]).to(device)\n",
        "        ckpt = torch.load(os.path.join(\n",
        "            modelConfig[\"save_dir\"], modelConfig[\"test_load_weight\"]), map_location=device)\n",
        "        model.load_state_dict(ckpt)\n",
        "        print(\"model load weight done.\")\n",
        "        model.eval()\n",
        "        sampler = GaussianDiffusionSampler(\n",
        "            model, modelConfig[\"beta_1\"], modelConfig[\"beta_T\"], modelConfig[\"T\"], w=modelConfig[\"w\"]).to(device)\n",
        "        # Sampled from standard normal distribution\n",
        "        noisyImage = torch.randn(\n",
        "            size=[modelConfig[\"batch_size\"], 3, modelConfig[\"img_size\"], modelConfig[\"img_size\"]], device=device)\n",
        "        saveNoisy = torch.clamp(noisyImage * 0.5 + 0.5, 0, 1)\n",
        "        save_image(saveNoisy, os.path.join(\n",
        "            modelConfig[\"sampled_dir\"],  modelConfig[\"sampledNoisyImgName\"]), nrow=modelConfig[\"nrow\"])\n",
        "        sampledImgs = sampler(noisyImage, labels)\n",
        "        sampledImgs = sampledImgs * 0.5 + 0.5  # [0 ~ 1]\n",
        "        print(sampledImgs)\n",
        "        save_image(sampledImgs, os.path.join(\n",
        "            modelConfig[\"sampled_dir\"],  modelConfig[\"sampledImgName\"]), nrow=modelConfig[\"nrow\"])"
      ],
      "metadata": {
        "id": "4t37yQvxYl05",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747042990794,
          "user_tz": 240,
          "elapsed": 334,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "4t37yQvxYl05",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelConfig = {\n",
        "    \"state\": \"eval\", # or eval\n",
        "    \"epoch\": 51,\n",
        "    \"batch_size\": 80,\n",
        "    \"T\": 500,\n",
        "    \"channel\": 128,\n",
        "    \"channel_mult\": [1, 2, 2, 2],\n",
        "    \"num_res_blocks\": 2,\n",
        "    \"dropout\": 0.15,\n",
        "    \"lr\": 1e-4,\n",
        "    \"multiplier\": 2.5,\n",
        "    \"beta_1\": 1e-4,\n",
        "    \"beta_T\": 0.028,\n",
        "    \"img_size\": 32,\n",
        "    \"grad_clip\": 1.,\n",
        "    \"device\": \"cuda:0\",\n",
        "    \"w\": 1.8,\n",
        "    \"save_dir\": \"./CheckpointsCondition3/\",\n",
        "    \"training_load_weight\": \"../CheckpointsCondition3/ckpt_18_.pt\",\n",
        "    \"test_load_weight\": \"ckpt_50_.pt\",\n",
        "    \"sampled_dir\": \"./SampledImgs/\",\n",
        "    \"sampledNoisyImgName\": \"NoisyGuidenceImgs.png\",\n",
        "    \"sampledImgName\": \"SampledGuidenceImgs.png\",\n",
        "    \"nrow\": 8\n",
        "}\n",
        "if modelConfig[\"state\"] == \"train\":\n",
        "    train(modelConfig)\n",
        "else:\n",
        "    eval(modelConfig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X5x-CvkY1s9",
        "outputId": "057b2060-a95a-4d22-c010-523b2cda8f85",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747062223777,
          "user_tz": 240,
          "elapsed": 105160,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "collapsed": true
      },
      "id": "4X5x-CvkY1s9",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,\n",
            "         3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,\n",
            "         5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,\n",
            "         7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
            "        10, 10, 10, 10, 10, 10, 10, 10], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-6bbdb3b5f02c>:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(os.path.join(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model load weight done.\n",
            "499\n",
            "498\n",
            "497\n",
            "496\n",
            "495\n",
            "494\n",
            "493\n",
            "492\n",
            "491\n",
            "490\n",
            "489\n",
            "488\n",
            "487\n",
            "486\n",
            "485\n",
            "484\n",
            "483\n",
            "482\n",
            "481\n",
            "480\n",
            "479\n",
            "478\n",
            "477\n",
            "476\n",
            "475\n",
            "474\n",
            "473\n",
            "472\n",
            "471\n",
            "470\n",
            "469\n",
            "468\n",
            "467\n",
            "466\n",
            "465\n",
            "464\n",
            "463\n",
            "462\n",
            "461\n",
            "460\n",
            "459\n",
            "458\n",
            "457\n",
            "456\n",
            "455\n",
            "454\n",
            "453\n",
            "452\n",
            "451\n",
            "450\n",
            "449\n",
            "448\n",
            "447\n",
            "446\n",
            "445\n",
            "444\n",
            "443\n",
            "442\n",
            "441\n",
            "440\n",
            "439\n",
            "438\n",
            "437\n",
            "436\n",
            "435\n",
            "434\n",
            "433\n",
            "432\n",
            "431\n",
            "430\n",
            "429\n",
            "428\n",
            "427\n",
            "426\n",
            "425\n",
            "424\n",
            "423\n",
            "422\n",
            "421\n",
            "420\n",
            "419\n",
            "418\n",
            "417\n",
            "416\n",
            "415\n",
            "414\n",
            "413\n",
            "412\n",
            "411\n",
            "410\n",
            "409\n",
            "408\n",
            "407\n",
            "406\n",
            "405\n",
            "404\n",
            "403\n",
            "402\n",
            "401\n",
            "400\n",
            "399\n",
            "398\n",
            "397\n",
            "396\n",
            "395\n",
            "394\n",
            "393\n",
            "392\n",
            "391\n",
            "390\n",
            "389\n",
            "388\n",
            "387\n",
            "386\n",
            "385\n",
            "384\n",
            "383\n",
            "382\n",
            "381\n",
            "380\n",
            "379\n",
            "378\n",
            "377\n",
            "376\n",
            "375\n",
            "374\n",
            "373\n",
            "372\n",
            "371\n",
            "370\n",
            "369\n",
            "368\n",
            "367\n",
            "366\n",
            "365\n",
            "364\n",
            "363\n",
            "362\n",
            "361\n",
            "360\n",
            "359\n",
            "358\n",
            "357\n",
            "356\n",
            "355\n",
            "354\n",
            "353\n",
            "352\n",
            "351\n",
            "350\n",
            "349\n",
            "348\n",
            "347\n",
            "346\n",
            "345\n",
            "344\n",
            "343\n",
            "342\n",
            "341\n",
            "340\n",
            "339\n",
            "338\n",
            "337\n",
            "336\n",
            "335\n",
            "334\n",
            "333\n",
            "332\n",
            "331\n",
            "330\n",
            "329\n",
            "328\n",
            "327\n",
            "326\n",
            "325\n",
            "324\n",
            "323\n",
            "322\n",
            "321\n",
            "320\n",
            "319\n",
            "318\n",
            "317\n",
            "316\n",
            "315\n",
            "314\n",
            "313\n",
            "312\n",
            "311\n",
            "310\n",
            "309\n",
            "308\n",
            "307\n",
            "306\n",
            "305\n",
            "304\n",
            "303\n",
            "302\n",
            "301\n",
            "300\n",
            "299\n",
            "298\n",
            "297\n",
            "296\n",
            "295\n",
            "294\n",
            "293\n",
            "292\n",
            "291\n",
            "290\n",
            "289\n",
            "288\n",
            "287\n",
            "286\n",
            "285\n",
            "284\n",
            "283\n",
            "282\n",
            "281\n",
            "280\n",
            "279\n",
            "278\n",
            "277\n",
            "276\n",
            "275\n",
            "274\n",
            "273\n",
            "272\n",
            "271\n",
            "270\n",
            "269\n",
            "268\n",
            "267\n",
            "266\n",
            "265\n",
            "264\n",
            "263\n",
            "262\n",
            "261\n",
            "260\n",
            "259\n",
            "258\n",
            "257\n",
            "256\n",
            "255\n",
            "254\n",
            "253\n",
            "252\n",
            "251\n",
            "250\n",
            "249\n",
            "248\n",
            "247\n",
            "246\n",
            "245\n",
            "244\n",
            "243\n",
            "242\n",
            "241\n",
            "240\n",
            "239\n",
            "238\n",
            "237\n",
            "236\n",
            "235\n",
            "234\n",
            "233\n",
            "232\n",
            "231\n",
            "230\n",
            "229\n",
            "228\n",
            "227\n",
            "226\n",
            "225\n",
            "224\n",
            "223\n",
            "222\n",
            "221\n",
            "220\n",
            "219\n",
            "218\n",
            "217\n",
            "216\n",
            "215\n",
            "214\n",
            "213\n",
            "212\n",
            "211\n",
            "210\n",
            "209\n",
            "208\n",
            "207\n",
            "206\n",
            "205\n",
            "204\n",
            "203\n",
            "202\n",
            "201\n",
            "200\n",
            "199\n",
            "198\n",
            "197\n",
            "196\n",
            "195\n",
            "194\n",
            "193\n",
            "192\n",
            "191\n",
            "190\n",
            "189\n",
            "188\n",
            "187\n",
            "186\n",
            "185\n",
            "184\n",
            "183\n",
            "182\n",
            "181\n",
            "180\n",
            "179\n",
            "178\n",
            "177\n",
            "176\n",
            "175\n",
            "174\n",
            "173\n",
            "172\n",
            "171\n",
            "170\n",
            "169\n",
            "168\n",
            "167\n",
            "166\n",
            "165\n",
            "164\n",
            "163\n",
            "162\n",
            "161\n",
            "160\n",
            "159\n",
            "158\n",
            "157\n",
            "156\n",
            "155\n",
            "154\n",
            "153\n",
            "152\n",
            "151\n",
            "150\n",
            "149\n",
            "148\n",
            "147\n",
            "146\n",
            "145\n",
            "144\n",
            "143\n",
            "142\n",
            "141\n",
            "140\n",
            "139\n",
            "138\n",
            "137\n",
            "136\n",
            "135\n",
            "134\n",
            "133\n",
            "132\n",
            "131\n",
            "130\n",
            "129\n",
            "128\n",
            "127\n",
            "126\n",
            "125\n",
            "124\n",
            "123\n",
            "122\n",
            "121\n",
            "120\n",
            "119\n",
            "118\n",
            "117\n",
            "116\n",
            "115\n",
            "114\n",
            "113\n",
            "112\n",
            "111\n",
            "110\n",
            "109\n",
            "108\n",
            "107\n",
            "106\n",
            "105\n",
            "104\n",
            "103\n",
            "102\n",
            "101\n",
            "100\n",
            "99\n",
            "98\n",
            "97\n",
            "96\n",
            "95\n",
            "94\n",
            "93\n",
            "92\n",
            "91\n",
            "90\n",
            "89\n",
            "88\n",
            "87\n",
            "86\n",
            "85\n",
            "84\n",
            "83\n",
            "82\n",
            "81\n",
            "80\n",
            "79\n",
            "78\n",
            "77\n",
            "76\n",
            "75\n",
            "74\n",
            "73\n",
            "72\n",
            "71\n",
            "70\n",
            "69\n",
            "68\n",
            "67\n",
            "66\n",
            "65\n",
            "64\n",
            "63\n",
            "62\n",
            "61\n",
            "60\n",
            "59\n",
            "58\n",
            "57\n",
            "56\n",
            "55\n",
            "54\n",
            "53\n",
            "52\n",
            "51\n",
            "50\n",
            "49\n",
            "48\n",
            "47\n",
            "46\n",
            "45\n",
            "44\n",
            "43\n",
            "42\n",
            "41\n",
            "40\n",
            "39\n",
            "38\n",
            "37\n",
            "36\n",
            "35\n",
            "34\n",
            "33\n",
            "32\n",
            "31\n",
            "30\n",
            "29\n",
            "28\n",
            "27\n",
            "26\n",
            "25\n",
            "24\n",
            "23\n",
            "22\n",
            "21\n",
            "20\n",
            "19\n",
            "18\n",
            "17\n",
            "16\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "11\n",
            "10\n",
            "9\n",
            "8\n",
            "7\n",
            "6\n",
            "5\n",
            "4\n",
            "3\n",
            "2\n",
            "1\n",
            "0\n",
            "tensor([[[[7.0398e-01, 6.9445e-01, 6.8478e-01,  ..., 5.7298e-01,\n",
            "           5.5535e-01, 5.5467e-01],\n",
            "          [6.9964e-01, 6.8951e-01, 6.8804e-01,  ..., 5.7491e-01,\n",
            "           5.6689e-01, 5.5966e-01],\n",
            "          [6.9414e-01, 6.9632e-01, 6.9867e-01,  ..., 5.7547e-01,\n",
            "           5.6614e-01, 5.5969e-01],\n",
            "          ...,\n",
            "          [4.4051e-01, 4.1545e-01, 4.2378e-01,  ..., 3.9397e-01,\n",
            "           3.6059e-01, 3.4435e-01],\n",
            "          [3.4737e-01, 3.3638e-01, 3.4944e-01,  ..., 3.0724e-01,\n",
            "           3.0569e-01, 3.0769e-01],\n",
            "          [3.3064e-01, 3.1581e-01, 3.2537e-01,  ..., 3.5444e-01,\n",
            "           3.4412e-01, 3.1986e-01]],\n",
            "\n",
            "         [[7.1906e-01, 7.1217e-01, 7.1690e-01,  ..., 5.9375e-01,\n",
            "           5.8004e-01, 5.7567e-01],\n",
            "          [7.2095e-01, 7.1538e-01, 7.1985e-01,  ..., 5.9135e-01,\n",
            "           5.8389e-01, 5.7898e-01],\n",
            "          [7.2012e-01, 7.1768e-01, 7.2646e-01,  ..., 5.9273e-01,\n",
            "           5.8525e-01, 5.7954e-01],\n",
            "          ...,\n",
            "          [3.0904e-01, 2.8546e-01, 2.7111e-01,  ..., 2.9487e-01,\n",
            "           2.7407e-01, 2.6907e-01],\n",
            "          [2.5545e-01, 2.6148e-01, 2.7649e-01,  ..., 2.1572e-01,\n",
            "           2.2751e-01, 2.3902e-01],\n",
            "          [2.5923e-01, 2.4325e-01, 2.4196e-01,  ..., 2.7395e-01,\n",
            "           2.6836e-01, 2.5825e-01]],\n",
            "\n",
            "         [[7.7288e-01, 7.6109e-01, 7.5982e-01,  ..., 6.5030e-01,\n",
            "           6.3211e-01, 6.2979e-01],\n",
            "          [7.7734e-01, 7.6628e-01, 7.6611e-01,  ..., 6.4967e-01,\n",
            "           6.3952e-01, 6.3196e-01],\n",
            "          [7.8107e-01, 7.7372e-01, 7.7792e-01,  ..., 6.4614e-01,\n",
            "           6.3791e-01, 6.2998e-01],\n",
            "          ...,\n",
            "          [2.4556e-01, 2.3156e-01, 2.0270e-01,  ..., 2.3363e-01,\n",
            "           2.2297e-01, 2.1374e-01],\n",
            "          [2.0292e-01, 2.1528e-01, 2.2549e-01,  ..., 1.6203e-01,\n",
            "           1.7730e-01, 1.8303e-01],\n",
            "          [2.0731e-01, 2.0200e-01, 2.0138e-01,  ..., 2.1998e-01,\n",
            "           2.1231e-01, 1.9322e-01]]],\n",
            "\n",
            "\n",
            "        [[[6.0810e-01, 5.8700e-01, 5.8456e-01,  ..., 5.4638e-01,\n",
            "           5.4017e-01, 5.5336e-01],\n",
            "          [6.2018e-01, 6.0008e-01, 5.9013e-01,  ..., 5.5912e-01,\n",
            "           5.5125e-01, 5.5882e-01],\n",
            "          [6.1629e-01, 6.0767e-01, 5.9641e-01,  ..., 5.7980e-01,\n",
            "           5.7286e-01, 5.7944e-01],\n",
            "          ...,\n",
            "          [7.4804e-01, 7.3764e-01, 7.4012e-01,  ..., 5.8794e-01,\n",
            "           5.9332e-01, 6.0010e-01],\n",
            "          [7.6597e-01, 7.4984e-01, 7.5087e-01,  ..., 5.7486e-01,\n",
            "           5.6707e-01, 5.8591e-01],\n",
            "          [7.7482e-01, 7.6000e-01, 7.5633e-01,  ..., 5.8617e-01,\n",
            "           5.9234e-01, 5.9822e-01]],\n",
            "\n",
            "         [[7.4976e-01, 7.3570e-01, 7.3490e-01,  ..., 7.2303e-01,\n",
            "           7.1791e-01, 7.1326e-01],\n",
            "          [7.6371e-01, 7.5188e-01, 7.4734e-01,  ..., 7.3772e-01,\n",
            "           7.3686e-01, 7.4034e-01],\n",
            "          [7.6226e-01, 7.5511e-01, 7.5044e-01,  ..., 7.4830e-01,\n",
            "           7.5502e-01, 7.5663e-01],\n",
            "          ...,\n",
            "          [8.5773e-01, 8.5148e-01, 8.4921e-01,  ..., 7.8746e-01,\n",
            "           7.8452e-01, 8.0433e-01],\n",
            "          [8.6487e-01, 8.5316e-01, 8.5485e-01,  ..., 7.9549e-01,\n",
            "           7.9446e-01, 7.9812e-01],\n",
            "          [8.6594e-01, 8.5550e-01, 8.5771e-01,  ..., 7.9562e-01,\n",
            "           8.0421e-01, 7.9267e-01]],\n",
            "\n",
            "         [[8.7008e-01, 8.4854e-01, 8.5035e-01,  ..., 8.5366e-01,\n",
            "           8.4614e-01, 8.6510e-01],\n",
            "          [8.8480e-01, 8.6729e-01, 8.6447e-01,  ..., 8.6053e-01,\n",
            "           8.6441e-01, 8.6743e-01],\n",
            "          [8.8383e-01, 8.7147e-01, 8.7003e-01,  ..., 8.7535e-01,\n",
            "           8.7649e-01, 8.7171e-01],\n",
            "          ...,\n",
            "          [9.1677e-01, 9.1482e-01, 9.1935e-01,  ..., 8.9575e-01,\n",
            "           8.9011e-01, 8.9405e-01],\n",
            "          [9.3135e-01, 9.2471e-01, 9.2653e-01,  ..., 8.9062e-01,\n",
            "           8.9336e-01, 8.9357e-01],\n",
            "          [9.3354e-01, 9.2599e-01, 9.2777e-01,  ..., 8.9646e-01,\n",
            "           9.1147e-01, 8.9843e-01]]],\n",
            "\n",
            "\n",
            "        [[[8.0256e-01, 8.0207e-01, 8.4396e-01,  ..., 9.6340e-01,\n",
            "           9.6030e-01, 9.7839e-01],\n",
            "          [8.1619e-01, 8.2010e-01, 8.4528e-01,  ..., 9.5698e-01,\n",
            "           9.5570e-01, 9.5650e-01],\n",
            "          [8.2505e-01, 8.3437e-01, 8.3947e-01,  ..., 9.5228e-01,\n",
            "           9.5492e-01, 9.6402e-01],\n",
            "          ...,\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 9.3145e-01,\n",
            "           9.2826e-01, 9.4002e-01],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 9.3347e-01,\n",
            "           9.2496e-01, 9.3515e-01],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 9.2946e-01,\n",
            "           9.2373e-01, 9.2967e-01]],\n",
            "\n",
            "         [[7.1136e-01, 7.1151e-01, 7.5760e-01,  ..., 8.7178e-01,\n",
            "           8.7812e-01, 8.8738e-01],\n",
            "          [7.1629e-01, 7.1927e-01, 7.4698e-01,  ..., 8.6647e-01,\n",
            "           8.6484e-01, 8.6903e-01],\n",
            "          [7.2559e-01, 7.2891e-01, 7.4897e-01,  ..., 8.5918e-01,\n",
            "           8.6118e-01, 8.6978e-01],\n",
            "          ...,\n",
            "          [9.9196e-01, 9.8706e-01, 9.9539e-01,  ..., 8.3974e-01,\n",
            "           8.3719e-01, 8.4290e-01],\n",
            "          [9.9349e-01, 9.9486e-01, 1.0000e+00,  ..., 8.3836e-01,\n",
            "           8.3084e-01, 8.3499e-01],\n",
            "          [9.8924e-01, 9.8563e-01, 9.7848e-01,  ..., 8.2809e-01,\n",
            "           8.2640e-01, 8.2541e-01]],\n",
            "\n",
            "         [[6.4901e-01, 6.5755e-01, 6.9899e-01,  ..., 8.2718e-01,\n",
            "           8.2659e-01, 8.2612e-01],\n",
            "          [6.6429e-01, 6.6143e-01, 6.6961e-01,  ..., 8.1965e-01,\n",
            "           8.2386e-01, 8.1795e-01],\n",
            "          [6.6022e-01, 6.5549e-01, 6.5910e-01,  ..., 8.1193e-01,\n",
            "           8.1937e-01, 8.2944e-01],\n",
            "          ...,\n",
            "          [9.9486e-01, 9.8563e-01, 9.9319e-01,  ..., 7.7061e-01,\n",
            "           7.5910e-01, 7.6424e-01],\n",
            "          [9.9834e-01, 9.9076e-01, 9.9309e-01,  ..., 7.7041e-01,\n",
            "           7.6128e-01, 7.6675e-01],\n",
            "          [9.9002e-01, 9.7487e-01, 9.8131e-01,  ..., 7.6464e-01,\n",
            "           7.5989e-01, 7.8307e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[4.5833e-01, 4.5723e-01, 4.6019e-01,  ..., 5.6884e-01,\n",
            "           5.6241e-01, 5.5523e-01],\n",
            "          [4.6690e-01, 4.5028e-01, 4.5999e-01,  ..., 5.4793e-01,\n",
            "           5.7972e-01, 6.1975e-01],\n",
            "          [5.0771e-01, 4.8819e-01, 4.8323e-01,  ..., 5.9637e-01,\n",
            "           6.6241e-01, 7.1633e-01],\n",
            "          ...,\n",
            "          [4.5567e-03, 6.4438e-03, 2.7420e-02,  ..., 8.8739e-01,\n",
            "           8.9610e-01, 9.0225e-01],\n",
            "          [6.2426e-03, 3.7819e-04, 1.4389e-02,  ..., 8.9649e-01,\n",
            "           8.9997e-01, 9.0519e-01],\n",
            "          [1.3392e-01, 4.1912e-02, 3.6887e-02,  ..., 8.8291e-01,\n",
            "           8.8069e-01, 8.8041e-01]],\n",
            "\n",
            "         [[8.3206e-01, 8.3227e-01, 8.3423e-01,  ..., 8.6600e-01,\n",
            "           8.5459e-01, 8.4735e-01],\n",
            "          [8.2560e-01, 8.1968e-01, 8.1908e-01,  ..., 8.5615e-01,\n",
            "           8.6131e-01, 8.7717e-01],\n",
            "          [8.3823e-01, 8.2638e-01, 8.2429e-01,  ..., 8.5240e-01,\n",
            "           8.8617e-01, 9.1282e-01],\n",
            "          ...,\n",
            "          [3.8682e-02, 2.4434e-02, 3.6427e-02,  ..., 8.9417e-01,\n",
            "           8.9610e-01, 9.0587e-01],\n",
            "          [2.7072e-02, 1.3119e-02, 2.5303e-02,  ..., 8.9859e-01,\n",
            "           8.9981e-01, 9.0460e-01],\n",
            "          [1.4198e-01, 5.1927e-02, 4.4422e-02,  ..., 8.8253e-01,\n",
            "           8.7506e-01, 8.7825e-01]],\n",
            "\n",
            "         [[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 9.9818e-01],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           9.9760e-01, 9.9808e-01],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 1.0000e+00],\n",
            "          ...,\n",
            "          [4.6611e-02, 4.2582e-02, 7.7007e-02,  ..., 8.9579e-01,\n",
            "           8.9707e-01, 9.0118e-01],\n",
            "          [5.0992e-02, 3.8243e-02, 5.7496e-02,  ..., 8.9638e-01,\n",
            "           8.9574e-01, 8.9876e-01],\n",
            "          [1.6215e-01, 6.7530e-02, 6.3205e-02,  ..., 8.8002e-01,\n",
            "           8.7058e-01, 8.7162e-01]]],\n",
            "\n",
            "\n",
            "        [[[9.9296e-01, 9.8120e-01, 9.8315e-01,  ..., 8.1160e-01,\n",
            "           7.7854e-01, 7.9633e-01],\n",
            "          [1.0000e+00, 1.0000e+00, 9.9768e-01,  ..., 8.3415e-01,\n",
            "           7.9974e-01, 8.1645e-01],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 9.0040e-01,\n",
            "           8.6447e-01, 7.8574e-01],\n",
            "          ...,\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           1.0000e+00, 9.9797e-01],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           9.9694e-01, 9.9677e-01],\n",
            "          [9.9477e-01, 9.9134e-01, 9.9636e-01,  ..., 9.8282e-01,\n",
            "           9.8085e-01, 9.8946e-01]],\n",
            "\n",
            "         [[9.8681e-01, 9.7714e-01, 9.8086e-01,  ..., 8.9154e-01,\n",
            "           8.5225e-01, 8.4092e-01],\n",
            "          [1.0000e+00, 9.9231e-01, 9.9014e-01,  ..., 9.0021e-01,\n",
            "           8.4988e-01, 8.3089e-01],\n",
            "          [1.0000e+00, 9.9878e-01, 9.9736e-01,  ..., 9.3462e-01,\n",
            "           8.7973e-01, 7.6896e-01],\n",
            "          ...,\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           9.9771e-01, 9.9457e-01],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
            "           9.9691e-01, 9.9473e-01],\n",
            "          [9.9974e-01, 9.9564e-01, 1.0000e+00,  ..., 9.8951e-01,\n",
            "           9.8582e-01, 9.9514e-01]],\n",
            "\n",
            "         [[9.8872e-01, 9.6920e-01, 9.7171e-01,  ..., 9.1209e-01,\n",
            "           8.6109e-01, 8.5274e-01],\n",
            "          [9.9826e-01, 9.8717e-01, 9.8506e-01,  ..., 9.1090e-01,\n",
            "           8.6098e-01, 8.2563e-01],\n",
            "          [1.0000e+00, 9.9623e-01, 9.9166e-01,  ..., 9.3917e-01,\n",
            "           8.7320e-01, 7.6563e-01],\n",
            "          ...,\n",
            "          [1.0000e+00, 9.9676e-01, 9.9554e-01,  ..., 9.9749e-01,\n",
            "           9.9538e-01, 9.8506e-01],\n",
            "          [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 9.9525e-01,\n",
            "           9.9217e-01, 9.8880e-01],\n",
            "          [9.9236e-01, 9.8660e-01, 9.9010e-01,  ..., 9.8385e-01,\n",
            "           9.7955e-01, 9.8534e-01]]],\n",
            "\n",
            "\n",
            "        [[[9.8306e-01, 9.8611e-01, 9.8471e-01,  ..., 8.6954e-01,\n",
            "           8.8708e-01, 8.2699e-01],\n",
            "          [9.8996e-01, 9.8863e-01, 9.8715e-01,  ..., 9.1566e-01,\n",
            "           9.6619e-01, 9.1512e-01],\n",
            "          [9.8450e-01, 9.8866e-01, 9.9264e-01,  ..., 8.4075e-01,\n",
            "           8.2240e-01, 7.8294e-01],\n",
            "          ...,\n",
            "          [5.4205e-01, 5.4673e-01, 5.5387e-01,  ..., 3.2096e-01,\n",
            "           3.5468e-01, 4.5628e-01],\n",
            "          [5.5966e-01, 5.3049e-01, 5.2111e-01,  ..., 2.1971e-01,\n",
            "           2.7526e-01, 4.1100e-01],\n",
            "          [5.5462e-01, 5.1099e-01, 5.1483e-01,  ..., 3.3132e-01,\n",
            "           3.7071e-01, 4.2200e-01]],\n",
            "\n",
            "         [[9.9679e-01, 9.8389e-01, 9.7831e-01,  ..., 5.9912e-01,\n",
            "           5.7011e-01, 5.2833e-01],\n",
            "          [9.9861e-01, 9.9014e-01, 9.9213e-01,  ..., 5.9713e-01,\n",
            "           6.3307e-01, 5.8860e-01],\n",
            "          [9.9277e-01, 1.0000e+00, 1.0000e+00,  ..., 5.5125e-01,\n",
            "           5.2759e-01, 4.8535e-01],\n",
            "          ...,\n",
            "          [6.0163e-01, 6.0238e-01, 5.9964e-01,  ..., 2.9205e-01,\n",
            "           3.1710e-01, 3.9247e-01],\n",
            "          [5.9553e-01, 5.8233e-01, 5.6885e-01,  ..., 1.9287e-01,\n",
            "           2.4300e-01, 3.5750e-01],\n",
            "          [5.7710e-01, 5.4057e-01, 5.1807e-01,  ..., 3.2270e-01,\n",
            "           3.6860e-01, 3.9923e-01]],\n",
            "\n",
            "         [[1.0000e+00, 9.9939e-01, 9.9146e-01,  ..., 4.5180e-01,\n",
            "           4.3009e-01, 3.5748e-01],\n",
            "          [1.0000e+00, 9.9649e-01, 9.9312e-01,  ..., 4.3368e-01,\n",
            "           4.6515e-01, 4.0798e-01],\n",
            "          [9.8930e-01, 9.9318e-01, 9.9601e-01,  ..., 4.0885e-01,\n",
            "           3.8070e-01, 3.4499e-01],\n",
            "          ...,\n",
            "          [6.1737e-01, 6.2688e-01, 6.2358e-01,  ..., 2.8486e-01,\n",
            "           3.0416e-01, 3.6613e-01],\n",
            "          [6.0382e-01, 5.9964e-01, 5.8757e-01,  ..., 2.0129e-01,\n",
            "           2.5520e-01, 3.7148e-01],\n",
            "          [5.4290e-01, 4.7736e-01, 4.6912e-01,  ..., 3.3702e-01,\n",
            "           3.8095e-01, 4.3020e-01]]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install lpips"
      ],
      "metadata": {
        "id": "05D4BqKyZqkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747062755801,
          "user_tz": 240,
          "elapsed": 2714,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "706c8004-3328-4790-f725-7a3ac86aab65"
      },
      "id": "05D4BqKyZqkC",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (3.0.2)\n",
            "Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l   \u001b[90m\u001b[0m \u001b[32m0.0/53.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import Dict\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy import linalg, stats\n",
        "import lpips\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision.models import inception_v3, Inception_V3_Weights\n",
        "from torch.nn import functional as F\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# \n",
        "# 1. METRIC FUNCTIONS\n",
        "# \n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load models\n",
        "weights = Inception_V3_Weights.DEFAULT\n",
        "_inception = inception_v3(weights=weights, aux_logits=True).to(device).eval()\n",
        "# and grab its recommended preprocessing transform:\n",
        "_incep_preprocess = weights.transforms()\n",
        "\n",
        "_lpips = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "def _get_inception_logits(x: torch.Tensor) -> torch.Tensor:\n",
        "    x_proc = _incep_preprocess(x)           # resize  crop  normalize\n",
        "    with torch.no_grad():\n",
        "      out = _inception(x_proc.to(device))\n",
        "    if isinstance(out, tuple):\n",
        "        out = out[0]                        # drop the aux_logits\n",
        "    return out\n",
        "\n",
        "def calculate_fid(mu1, sigma1, mu2, sigma2):\n",
        "    diff = mu1 - mu2\n",
        "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
        "    covmean = covmean.real if np.iscomplexobj(covmean) else covmean\n",
        "    return diff.dot(diff) + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
        "\n",
        "def compute_fid(real: torch.Tensor, fake: torch.Tensor) -> float:\n",
        "    act_real = _get_inception_logits(real).cpu().numpy()\n",
        "    act_fake = _get_inception_logits(fake).cpu().numpy()\n",
        "    mu_r, sigma_r = act_real.mean(0), np.cov(act_real, rowvar=False)\n",
        "    mu_f, sigma_f = act_fake.mean(0), np.cov(act_fake, rowvar=False)\n",
        "    return calculate_fid(mu_r, sigma_r, mu_f, sigma_f)\n",
        "\n",
        "def compute_inception_score(fake: torch.Tensor, splits=10):\n",
        "    preds = F.softmax(_get_inception_logits(fake), dim=1).cpu().numpy()\n",
        "    N = preds.shape[0]\n",
        "    scores = []\n",
        "    for k in range(splits):\n",
        "        part = preds[k*(N//splits):(k+1)*(N//splits)]\n",
        "        py = part.mean(axis=0)\n",
        "        scores.append(np.exp(np.mean([stats.entropy(p, py) for p in part])))\n",
        "    return float(np.mean(scores)), float(np.std(scores))\n",
        "\n",
        "def compute_lpips(real: torch.Tensor, fake: torch.Tensor) -> float:\n",
        "    # LPIPS expects input in [-1,+1]\n",
        "    r = 2*real - 1\n",
        "    f = 2*fake - 1\n",
        "    with torch.no_grad():\n",
        "        return float(_lpips(f.to(device), r.to(device)).mean())\n",
        "\n",
        "def evaluate_all(real: torch.Tensor, fake: torch.Tensor) -> Dict[str, float]:\n",
        "    return {\n",
        "        \"FID\": compute_fid(real, fake),\n",
        "        \"IS_mean\": compute_inception_score(fake)[0],\n",
        "        \"IS_std\":  compute_inception_score(fake)[1],\n",
        "        \"LPIPS\": compute_lpips(real, fake),\n",
        "    }\n",
        "\n",
        "# \n",
        "# 2. REAL CIFAR-10 LOADER\n",
        "# \n",
        "\n",
        "def load_cifar10_test(num_samples: int):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      real_images: Tensor [num_samples,3,32,32] in [0,1]\n",
        "      real_labels: Tensor [num_samples]\n",
        "    \"\"\"\n",
        "    ds = CIFAR10(root=\"./data\", train=False, download=True,\n",
        "                 transform=transforms.ToTensor())\n",
        "    if num_samples < len(ds):\n",
        "        ds = Subset(ds, list(range(num_samples)))\n",
        "    loader = DataLoader(ds, batch_size=num_samples, shuffle=False)\n",
        "    imgs, labs = next(iter(loader))\n",
        "    return imgs.to(device), labs.to(device)\n",
        "\n",
        "# \n",
        "# 3. EXTENDED eval() WITH METRICS\n",
        "# \n",
        "\n",
        "def eval_with_metrics(modelConfig: Dict):\n",
        "    device = torch.device(modelConfig[\"device\"])\n",
        "    B = modelConfig[\"batch_size\"]\n",
        "\n",
        "    # --- load real CIFAR-10 test images\n",
        "    real_images, real_labels = load_cifar10_test(num_samples=B)\n",
        "    print(f\"Loaded {real_images.shape[0]} real CIFAR-10 test images.\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # build label tensor [0..9] repeated\n",
        "        step = B // 10\n",
        "        label_list = []\n",
        "        for k in range(10):\n",
        "            label_list += [torch.full((step,), k, dtype=torch.long)]\n",
        "        labels = torch.cat(label_list, dim=0).to(device)\n",
        "        print(\"Labels tensor:\", labels.shape)\n",
        "\n",
        "        # instantiate and load weights\n",
        "        model = UNet(\n",
        "            T=modelConfig[\"T\"],\n",
        "            num_labels=10,\n",
        "            ch=modelConfig[\"channel\"],\n",
        "            ch_mult=modelConfig[\"channel_mult\"],\n",
        "            num_res_blocks=modelConfig[\"num_res_blocks\"],\n",
        "            dropout=modelConfig[\"dropout\"]\n",
        "        ).to(device)\n",
        "        ckpt = torch.load(\n",
        "            os.path.join(modelConfig[\"save_dir\"], modelConfig[\"test_load_weight\"]),\n",
        "            map_location=device\n",
        "        )\n",
        "        model.load_state_dict(ckpt)\n",
        "        model.eval()\n",
        "        print(\"Model loaded.\")\n",
        "\n",
        "        # sampler\n",
        "        sampler = GaussianDiffusionSampler(\n",
        "            model,\n",
        "            modelConfig[\"beta_1\"],\n",
        "            modelConfig[\"beta_T\"],\n",
        "            modelConfig[\"T\"],\n",
        "            w=modelConfig[\"w\"]\n",
        "        ).to(device)\n",
        "\n",
        "        # sample from N(0,I)\n",
        "        noisy = torch.randn(\n",
        "            B, 3, modelConfig[\"img_size\"], modelConfig[\"img_size\"],\n",
        "            device=device\n",
        "        )\n",
        "        sampled = sampler(noisy, labels)\n",
        "        sampled = sampled.clamp(-0.5, +0.5) + 0.5   # to [0,1]\n",
        "        print(f\"Generated {sampled.shape[0]} fake images.\")\n",
        "\n",
        "        # (optional) save a grid\n",
        "        save_image(\n",
        "            sampled,\n",
        "            os.path.join(modelConfig[\"sampled_dir\"], modelConfig[\"sampledImgName\"]),\n",
        "            nrow=modelConfig[\"nrow\"]\n",
        "        )\n",
        "\n",
        "    # --- compute metrics\n",
        "    metrics = evaluate_all(real_images, sampled)\n",
        "    print(\"=== Evaluation Metrics ===\")\n",
        "    for k,v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def main(model_config=None):\n",
        "    modelConfig = {\n",
        "        \"state\": \"eval\", # or eval\n",
        "        \"epoch\": 70,\n",
        "        \"batch_size\": 80,\n",
        "        \"T\": 500,\n",
        "        \"channel\": 128,\n",
        "        \"channel_mult\": [1, 2, 2, 2],\n",
        "        \"num_res_blocks\": 2,\n",
        "        \"dropout\": 0.15,\n",
        "        \"lr\": 1e-4,\n",
        "        \"multiplier\": 2.5,\n",
        "        \"beta_1\": 1e-4,\n",
        "        \"beta_T\": 0.028,\n",
        "        \"img_size\": 32,\n",
        "        \"grad_clip\": 1.,\n",
        "        \"device\": \"cuda:0\",\n",
        "        \"w\": 1.8,\n",
        "        \"save_dir\": \"./CheckpointsCondition3/\",\n",
        "        \"training_load_weight\": \"../CheckpointsCondition3/ckpt_18_.pt\",\n",
        "        \"test_load_weight\": \"ckpt_50_.pt\",\n",
        "        \"sampled_dir\": \"./SampledImgs/\",\n",
        "        \"sampledNoisyImgName\": \"NoisyGuidenceImgs.png\",\n",
        "        \"sampledImgName\": \"SampledGuidenceImgs.png\",\n",
        "        \"nrow\": 8\n",
        "    }\n",
        "    if model_config is not None:\n",
        "        modelConfig = model_config\n",
        "    if modelConfig[\"state\"] == \"train\":\n",
        "        training_loss = train(modelConfig)  # new\n",
        "        print(training_loss)  # new\n",
        "    else:\n",
        "        metrics = eval_with_metrics(modelConfig)\n",
        "        print(metrics)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXRiMe0FDgDe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1747064338878,
          "user_tz": 240,
          "elapsed": 108418,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "1271439c-9a73-48bd-a172-655bc6681e67"
      },
      "id": "OXRiMe0FDgDe",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "Files already downloaded and verified\n",
            "Loaded 80 real CIFAR-10 test images.\n",
            "Labels tensor: torch.Size([80])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-8586fe368ebf>:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded.\n",
            "499\n",
            "498\n",
            "497\n",
            "496\n",
            "495\n",
            "494\n",
            "493\n",
            "492\n",
            "491\n",
            "490\n",
            "489\n",
            "488\n",
            "487\n",
            "486\n",
            "485\n",
            "484\n",
            "483\n",
            "482\n",
            "481\n",
            "480\n",
            "479\n",
            "478\n",
            "477\n",
            "476\n",
            "475\n",
            "474\n",
            "473\n",
            "472\n",
            "471\n",
            "470\n",
            "469\n",
            "468\n",
            "467\n",
            "466\n",
            "465\n",
            "464\n",
            "463\n",
            "462\n",
            "461\n",
            "460\n",
            "459\n",
            "458\n",
            "457\n",
            "456\n",
            "455\n",
            "454\n",
            "453\n",
            "452\n",
            "451\n",
            "450\n",
            "449\n",
            "448\n",
            "447\n",
            "446\n",
            "445\n",
            "444\n",
            "443\n",
            "442\n",
            "441\n",
            "440\n",
            "439\n",
            "438\n",
            "437\n",
            "436\n",
            "435\n",
            "434\n",
            "433\n",
            "432\n",
            "431\n",
            "430\n",
            "429\n",
            "428\n",
            "427\n",
            "426\n",
            "425\n",
            "424\n",
            "423\n",
            "422\n",
            "421\n",
            "420\n",
            "419\n",
            "418\n",
            "417\n",
            "416\n",
            "415\n",
            "414\n",
            "413\n",
            "412\n",
            "411\n",
            "410\n",
            "409\n",
            "408\n",
            "407\n",
            "406\n",
            "405\n",
            "404\n",
            "403\n",
            "402\n",
            "401\n",
            "400\n",
            "399\n",
            "398\n",
            "397\n",
            "396\n",
            "395\n",
            "394\n",
            "393\n",
            "392\n",
            "391\n",
            "390\n",
            "389\n",
            "388\n",
            "387\n",
            "386\n",
            "385\n",
            "384\n",
            "383\n",
            "382\n",
            "381\n",
            "380\n",
            "379\n",
            "378\n",
            "377\n",
            "376\n",
            "375\n",
            "374\n",
            "373\n",
            "372\n",
            "371\n",
            "370\n",
            "369\n",
            "368\n",
            "367\n",
            "366\n",
            "365\n",
            "364\n",
            "363\n",
            "362\n",
            "361\n",
            "360\n",
            "359\n",
            "358\n",
            "357\n",
            "356\n",
            "355\n",
            "354\n",
            "353\n",
            "352\n",
            "351\n",
            "350\n",
            "349\n",
            "348\n",
            "347\n",
            "346\n",
            "345\n",
            "344\n",
            "343\n",
            "342\n",
            "341\n",
            "340\n",
            "339\n",
            "338\n",
            "337\n",
            "336\n",
            "335\n",
            "334\n",
            "333\n",
            "332\n",
            "331\n",
            "330\n",
            "329\n",
            "328\n",
            "327\n",
            "326\n",
            "325\n",
            "324\n",
            "323\n",
            "322\n",
            "321\n",
            "320\n",
            "319\n",
            "318\n",
            "317\n",
            "316\n",
            "315\n",
            "314\n",
            "313\n",
            "312\n",
            "311\n",
            "310\n",
            "309\n",
            "308\n",
            "307\n",
            "306\n",
            "305\n",
            "304\n",
            "303\n",
            "302\n",
            "301\n",
            "300\n",
            "299\n",
            "298\n",
            "297\n",
            "296\n",
            "295\n",
            "294\n",
            "293\n",
            "292\n",
            "291\n",
            "290\n",
            "289\n",
            "288\n",
            "287\n",
            "286\n",
            "285\n",
            "284\n",
            "283\n",
            "282\n",
            "281\n",
            "280\n",
            "279\n",
            "278\n",
            "277\n",
            "276\n",
            "275\n",
            "274\n",
            "273\n",
            "272\n",
            "271\n",
            "270\n",
            "269\n",
            "268\n",
            "267\n",
            "266\n",
            "265\n",
            "264\n",
            "263\n",
            "262\n",
            "261\n",
            "260\n",
            "259\n",
            "258\n",
            "257\n",
            "256\n",
            "255\n",
            "254\n",
            "253\n",
            "252\n",
            "251\n",
            "250\n",
            "249\n",
            "248\n",
            "247\n",
            "246\n",
            "245\n",
            "244\n",
            "243\n",
            "242\n",
            "241\n",
            "240\n",
            "239\n",
            "238\n",
            "237\n",
            "236\n",
            "235\n",
            "234\n",
            "233\n",
            "232\n",
            "231\n",
            "230\n",
            "229\n",
            "228\n",
            "227\n",
            "226\n",
            "225\n",
            "224\n",
            "223\n",
            "222\n",
            "221\n",
            "220\n",
            "219\n",
            "218\n",
            "217\n",
            "216\n",
            "215\n",
            "214\n",
            "213\n",
            "212\n",
            "211\n",
            "210\n",
            "209\n",
            "208\n",
            "207\n",
            "206\n",
            "205\n",
            "204\n",
            "203\n",
            "202\n",
            "201\n",
            "200\n",
            "199\n",
            "198\n",
            "197\n",
            "196\n",
            "195\n",
            "194\n",
            "193\n",
            "192\n",
            "191\n",
            "190\n",
            "189\n",
            "188\n",
            "187\n",
            "186\n",
            "185\n",
            "184\n",
            "183\n",
            "182\n",
            "181\n",
            "180\n",
            "179\n",
            "178\n",
            "177\n",
            "176\n",
            "175\n",
            "174\n",
            "173\n",
            "172\n",
            "171\n",
            "170\n",
            "169\n",
            "168\n",
            "167\n",
            "166\n",
            "165\n",
            "164\n",
            "163\n",
            "162\n",
            "161\n",
            "160\n",
            "159\n",
            "158\n",
            "157\n",
            "156\n",
            "155\n",
            "154\n",
            "153\n",
            "152\n",
            "151\n",
            "150\n",
            "149\n",
            "148\n",
            "147\n",
            "146\n",
            "145\n",
            "144\n",
            "143\n",
            "142\n",
            "141\n",
            "140\n",
            "139\n",
            "138\n",
            "137\n",
            "136\n",
            "135\n",
            "134\n",
            "133\n",
            "132\n",
            "131\n",
            "130\n",
            "129\n",
            "128\n",
            "127\n",
            "126\n",
            "125\n",
            "124\n",
            "123\n",
            "122\n",
            "121\n",
            "120\n",
            "119\n",
            "118\n",
            "117\n",
            "116\n",
            "115\n",
            "114\n",
            "113\n",
            "112\n",
            "111\n",
            "110\n",
            "109\n",
            "108\n",
            "107\n",
            "106\n",
            "105\n",
            "104\n",
            "103\n",
            "102\n",
            "101\n",
            "100\n",
            "99\n",
            "98\n",
            "97\n",
            "96\n",
            "95\n",
            "94\n",
            "93\n",
            "92\n",
            "91\n",
            "90\n",
            "89\n",
            "88\n",
            "87\n",
            "86\n",
            "85\n",
            "84\n",
            "83\n",
            "82\n",
            "81\n",
            "80\n",
            "79\n",
            "78\n",
            "77\n",
            "76\n",
            "75\n",
            "74\n",
            "73\n",
            "72\n",
            "71\n",
            "70\n",
            "69\n",
            "68\n",
            "67\n",
            "66\n",
            "65\n",
            "64\n",
            "63\n",
            "62\n",
            "61\n",
            "60\n",
            "59\n",
            "58\n",
            "57\n",
            "56\n",
            "55\n",
            "54\n",
            "53\n",
            "52\n",
            "51\n",
            "50\n",
            "49\n",
            "48\n",
            "47\n",
            "46\n",
            "45\n",
            "44\n",
            "43\n",
            "42\n",
            "41\n",
            "40\n",
            "39\n",
            "38\n",
            "37\n",
            "36\n",
            "35\n",
            "34\n",
            "33\n",
            "32\n",
            "31\n",
            "30\n",
            "29\n",
            "28\n",
            "27\n",
            "26\n",
            "25\n",
            "24\n",
            "23\n",
            "22\n",
            "21\n",
            "20\n",
            "19\n",
            "18\n",
            "17\n",
            "16\n",
            "15\n",
            "14\n",
            "13\n",
            "12\n",
            "11\n",
            "10\n",
            "9\n",
            "8\n",
            "7\n",
            "6\n",
            "5\n",
            "4\n",
            "3\n",
            "2\n",
            "1\n",
            "0\n",
            "Generated 80 fake images.\n",
            "=== Evaluation Metrics ===\n",
            "FID: 681.9204\n",
            "IS_mean: 2.4277\n",
            "IS_std: 0.4468\n",
            "LPIPS: 0.2234\n",
            "{'FID': 681.9203928195238, 'IS_mean': 2.427720785140991, 'IS_std': 0.44676727056503296, 'LPIPS': 0.22339175641536713}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "base",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}